{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('~/Documents/Titanic_project'):\n",
    "\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT LIBRARIES\n",
    "import seaborn as sns #library visualization\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD THE DATA\n",
    "\n",
    "df_train = pd.read_csv('~/Documents/Titanic_project/titanicproject/train.csv')\n",
    "df_test = pd.read_csv('~/Documents/Titanic_project/titanicproject/test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHOW FIRST 10 ROWS (TRAIN DATA)\n",
    "df_train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHOW FIRST 5 ROWS (TEST DATA)\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Null values (TRAIN DATA)\n",
    "print(\"Columns with missing values: \")\n",
    "print(df_train.columns[df_train.isnull().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Null values (TEST DATA)\n",
    "print(\"Columns with missing values: \")\n",
    "print(df_test.columns[df_test.isnull().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "source": [
    "# 3 ways to handle null values\n",
    "\n",
    "#1.Remove NaN rows \n",
    "#2.Set NaN to hard coded value \n",
    "#3.Impute NaN values based on other rows\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING NaN ROWS\n",
    "print(\"Before dropping - \" + str(len(df_train)) + \" rows\")\n",
    "df_train = df_train[~df_train['Embarked'].isna()]\n",
    "print(\"After dropping - \" + str(len(df_train)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILL NaN WITH MEAN VALUE\n",
    "mean_fare = df_test['Fare'].mean()\n",
    "print(\"Mean value of fare = \" + str(mean_fare))\n",
    "print(\"NA count before fill = \" + str(len(df_test[df_test['Fare'].isna()])))\n",
    "df_test['Fare'] = df_test['Fare'].fillna(mean_fare)\n",
    "print(\"NA count after fill = \" + str(len(df_test[df_test['Fare'].isna()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILL NaN WITH MEAN VALUE (TRAIN DATA)\n",
    "mean_age = df_train['Age'].mean()\n",
    "print(\"Mean age of passengers = \" + str(mean_age))\n",
    "print(\"NA count before fill = \" + str(len(df_train[df_train['Age'].isna()])))\n",
    "df_train['Age'] = df_train['Age'].fillna(mean_age)\n",
    "print(\"NA count after fill = \" + str(len(df_train[df_train['Age'].isna()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILL NaN WITH MEAN VALUE (TEST DATA)\n",
    "mean_age = df_test['Age'].mean()\n",
    "print(\"Mean age of passengers = \" + str(mean_age))\n",
    "print(\"NA count before fill = \" + str(len(df_test[df_test['Age'].isna()])))\n",
    "df_test['Age'] = df_test['Age'].fillna(mean_age)\n",
    "print(\"NA count after fill = \" + str(len(df_test[df_test['Age'].isna()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical distribution\n",
    "df_train.describe()"
   ]
  },
  {
   "source": [
    "hist = df_train.hist(figsize=(10,10),layout=(3,4))\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "sns.pairplot(df_train)\n",
    "plt.show()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=df_train.corr()\n",
    "\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "Correaltions observed in Titanic:\n",
    "\n",
    "Pclass and Fare Age and Parch Age and SibSp Age and Pclass Pclass and Survived"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING - GET RELATIVE COUNT BY SUMMING 'SibSp' &  'Parch'\n",
    "df_train['RelativeCount'] = df_train['SibSp'] + df_train['Parch']\n",
    "df_test['RelativeCount'] = df_test['SibSp'] + df_test['Parch']\n",
    "df_train['RelativeCount'].describe()\n",
    "df_test.head(5)\n"
   ]
  },
  {
   "source": [
    "Was a passenger travelling alone?\n",
    "\n",
    "numpy.where(): Return elements chosen from x or y depending on condition. https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING - GET \"Was a passenger travelling alone?\" \n",
    "df_train['TravelAlone'] = np.where(df_train['SibSp']+df_train['Parch']>0, 0, 1)\n",
    "df_test['TravelAlone'] = np.where(df_test['SibSp']+df_test['Parch']>0, 0, 1)\n",
    "# No - 0 , YES - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE 'Age' CONVERT TO CATEGORICAL VALUE - AGEBUCKETING\n",
    "def bucket_age(age):\n",
    "  if age < 15:\n",
    "    return \"<15\"\n",
    "  if age >= 15 and age < 30:\n",
    "    return \"15-30\"\n",
    "  if age >=30 and age < 45:\n",
    "    return \"30-45\"\n",
    "  if age>=45 and age < 60:\n",
    "    return \"45-60\"\n",
    "  return \">60\"\n",
    "\n",
    "df_train['AgeBucket'] = df_train['Age'].apply(bucket_age)\n",
    "df_test['AgeBucket'] = df_test['Age'].apply(bucket_age)\n",
    "\n",
    "#Visualising with a pie chart\n",
    "print('TRAIN:')\n",
    "pie = df_train['AgeBucket'].value_counts().plot(kind=\"pie\",title='AgeBucket Distribution',legend=True,autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TEST:')\n",
    "pie_test = df_test['AgeBucket'].value_counts().plot(kind=\"pie\",title='AgeBucket Distribution',legend=True,autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING NAME LENGTH FROM FEATURE 'Name'\n",
    "\n",
    "df_train['Name_Length'] = df_train['Name'].apply(lambda x : len(x))\n",
    "df_train['Name_Length'] = (df_train.Name_Length).astype(np.int64)+1\n",
    "\n",
    "# PLOTTING\n",
    "plt.subplots(figsize=(15, 6))\n",
    "sns.barplot(data=df_train,x='Name_Length',y='Survived')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Name_Length'] = df_test['Name'].apply(lambda x : len(x))\n",
    "df_test['Name_Length'] = (df_test.Name_Length).astype(np.int64)+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING TITLE FROM A NAME (TRAIN DATA)\n",
    "title = df_train.Name.values\n",
    "import re\n",
    "for i,t in enumerate(title):\n",
    "    r = re.search(',([A-Za-z ]*)',t)\n",
    "    title[i] = r.group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING TITLE FROM NAME (TEST DATA)\n",
    "title = df_test.Name.values\n",
    "\n",
    "for i,t in enumerate(title):\n",
    "    r = re.search(',([A-Za-z ]*)',t)\n",
    "    title[i] = r.group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to encode the text values by putting a running sequence for each text values from whole dataset, we first concatenate df_train and df_test before label encoding\n",
    "all_data = pd.concat([df_train, df_test])\n",
    "all_data.shape"
   ]
  },
  {
   "source": [
    "# SEX -LABEL ENCODING \n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "trained_le = le.fit(all_data.Sex)\n",
    "df_train['Sex'] = trained_le.transform(df_train.Sex)\n",
    "df_test['Sex'] = trained_le.transform(df_test.Sex)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBARKED -LABEL ENCODING\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "trained_le = le.fit(all_data.Embarked)\n",
    "df_train['Embarked'] = trained_le.transform(df_train.Embarked)\n",
    "df_test['Embarked'] = trained_le.transform(df_test.Embarked)\n"
   ]
  },
  {
   "source": [
    "# AGE_BUCKET - LABEL ENCODING\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "trained_le = le.fit(all_data.AgeBucket)\n",
    "df_train['AgeBucket'] = trained_le.transform(df_train.AgeBucket)\n",
    "df_test['AgeBucket'] = trained_le.transform(df_test.AgeBucket)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMMY ENCODING \n",
    "agebucket_dummies=pd.get_dummies(df_train.AgeBucket, prefix='AgeBucket')\n",
    "df_train=pd.concat([df_train,agebucket_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agebucket_dummies=pd.get_dummies(df_test.AgeBucket, prefix='AgeBucket')\n",
    "df_test=pd.concat([df_test,agebucket_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Fare'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 'Fare' CONVERT TO CATEGORICAL VALUE \n",
    "def bucket_Fare(Fare):\n",
    "  if Fare < 100:\n",
    "    return \"<100\"\n",
    "  if Fare >= 100 and Fare < 200:\n",
    "    return \"100-200\"\n",
    "  if Fare >=200 and Fare < 300:\n",
    "    return \"200-300\"\n",
    "  if Fare>=300 and Fare < 400:\n",
    "    return \"300-400\"\n",
    "  return \">400\"\n",
    "\n",
    "df_train['FareBucket'] = df_train['Fare'].apply(bucket_Fare)\n",
    "df_test['FareBucket'] = df_test['Fare'].apply(bucket_Fare)\n",
    "\n",
    "#Visualize this with a pie chart\n",
    "print('TRAIN:')\n",
    "pie = df_train['FareBucket'].value_counts().plot(kind=\"pie\",title='FareBucket Distribution',legend=True,autopct='%1.1f%%')\n",
    "#pie = df_test['FareBucket'].value_counts().plot(kind=\"pie\",title='FareBucket Distribution',legend=True,autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie = df_test['FareBucket'].value_counts().plot(kind=\"pie\",title='FareBucket Distribution',legend=True,autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([df_train, df_test])\n"
   ]
  },
  {
   "source": [
    "# FareBucket - LABEL ENCODING\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "trained_le = le.fit(all_data.FareBucket)\n",
    "df_train['FareBucket'] = trained_le.transform(df_train.FareBucket)\n",
    "df_test['FareBucket'] = trained_le.transform(df_test.FareBucket)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMMY ENCODING\n",
    "sex_dummies=pd.get_dummies(df_train.Sex, prefix='Sex')\n",
    "df_train=pd.concat([df_train,sex_dummies],axis=1)\n",
    "\n",
    "sex_dummies=pd.get_dummies(df_test.Sex, prefix='Sex')\n",
    "df_test=pd.concat([df_test,sex_dummies],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_dummies=pd.get_dummies(df_train.Embarked, prefix='Embarked')\n",
    "df_train=pd.concat([df_train,embarked_dummies],axis=1)\n",
    "\n",
    "embarked_dummies=pd.get_dummies(df_test.Embarked, prefix='Embarked')\n",
    "df_test=pd.concat([df_test,embarked_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING FIRST CHARACTER FROM 'Cabin' (TRAIN DATA)\n",
    "New_cabin = df_train['Cabin'].astype(str).str[0]\n",
    "df = pd.DataFrame(New_cabin)\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# DROPPING Cabin (TRAIN DATA)\n",
    "df_train.drop(labels=['Cabin'],axis=1,inplace=True)\n",
    "df_train=pd.concat([df_train,df],axis=1)\n",
    "df_train.head(5)\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#EXTRACTING FIRST CHARACTER FROM 'Cabin' (TEST DATA)\n",
    "New_cabin = df_test['Cabin'].astype(str).str[0]\n",
    "df = pd.DataFrame(New_cabin)\n",
    "df_test.drop(labels=['Cabin'],axis=1,inplace=True)\n",
    "df_test=pd.concat([df_test,df],axis=1)\n",
    "df_test.head(5)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "New_cabin = all_data['Cabin'].astype(str).str[0]\n",
    "df = pd.DataFrame(New_cabin)\n",
    "all_data.drop(labels=['Cabin'],axis=1,inplace=True)\n",
    "all_data=pd.concat([all_data,df],axis=1)\n",
    "\n",
    "all_data.Cabin.unique()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DICTIONARY WITH UNIQUE VALUES FROM 'Cabin' (ALL_DATA) & MAP VALUES FROM 'Cabin' (TRAIN DATA)\n",
    "Temp_dict = {'n' : 1, 'C' : 7, 'E': 5, 'G': 4, 'D': 6, 'A': 9, 'B': 8, 'F': 3 , 'T': 2}\n",
    "df_train['NewCabin'] = df_train.Cabin.map(Temp_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['NewCabin'] = df_test.Cabin.map(Temp_dict)\n"
   ]
  },
  {
   "source": [
    "# DROPPING COLUMNS: CABIN, TICKET, FARE, SEX, NAME, EMBARKED, AGEBUCKET\n",
    "df_train.drop(labels=['Cabin','Ticket','Fare','Sex', 'Name', 'Embarked', 'AgeBucket' ],axis=1,inplace=True)\n",
    "df_test.drop(labels=['Cabin','Ticket','Fare','Sex','Name', 'Embarked', 'AgeBucket'],axis=1,inplace=True)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#DIVIDING THE DATA INTO Y_TRAIN AND X_TRAIN AND CONVERTING THEM INTO NP ARRAYS\n",
    "y_train = df_train.loc[:,'Survived'].values\n",
    "x_train =df_train.drop(['Survived'],axis=1).values\n",
    "x_test = df_test.values\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "dict_K = {}\n",
    "dic = {}\n",
    "\n",
    "#Kfold Validation\n",
    "def get_acc(Xtrain,Ytrain,model):\n",
    "    from sklearn.model_selection import KFold\n",
    "    acc = []\n",
    "    k=KFold(n_splits=4)\n",
    "    for train , test in k.split(Xtrain,y=Ytrain):\n",
    "        x_train = Xtrain[train,:]\n",
    "        y_train = Ytrain[train]\n",
    "        x_test = Xtrain[test,:]\n",
    "        y_test = Ytrain[test]\n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "        acc.append((cm[1,1]+cm[0,0])/((cm[1,0]+cm[0,1]+cm[1,1]+cm[0,0])+1e-5))\n",
    "    return acc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100,criterion='entropy')\n",
    "dict_K['Random_forest'] = get_acc(x_train,y_train,classifier)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F = pd.DataFrame(dict_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICT RESULTS\n",
    "df_F.mean()"
   ]
  },
  {
   "source": [
    "# SUBMIT RESULTS\n",
    "p = df_test.PassengerId\n",
    "p = pd.concat([p,pd.DataFrame(y_pred.astype(np.int64),columns=['Survived'])],axis=1)\n",
    "p.to_csv('Surv_predF.csv',index=False)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}